name: Full Data Pipeline

on:
  schedule:
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      target_branch:
        description: 'Target branch for pull request'
        required: false
        default: 'main'
        type: string

permissions:
  contents: write
  pull-requests: write

concurrency:
  group: full-data-pipeline
  cancel-in-progress: true

jobs:
  run-full-pipeline:
    runs-on: self-hosted

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0
          persist-credentials: true

      - name: Activate venv and run full data pipeline
        env:
          API_SECRET: ${{ secrets.API_SECRET }}
          BASE_URL: ${{ secrets.BASE_URL }}
        run: |
          source $HOME/sg/bin/activate
          python data/operations/full_data_pipeline.py

      - name: Commit and push generated artifacts
        run: |
          git config --local user.email "mohamed.orabi@studentgator.com"
          git config --local user.name "mohammed-orabi2"

          # Always align with remote main
          git fetch origin
          git reset --hard origin/main

          # Add ONLY generated files
          git add data/vector_store/
          git add data/chroma_documents/*.json

          if git diff --staged --quiet; then
            echo "No changes detected"
            echo "has_changes=false" >> $GITHUB_ENV
          else
            git commit -m "Update generated VDB & chroma docs - $(date -u +"%Y-%m-%d %H:%M UTC")"
            git push origin main --force-with-lease
            echo "has_changes=true" >> $GITHUB_ENV
          fi
